{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ef9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_cpp import Llama\n",
    "from statistics import mean\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from Libraries import Common_Utils as UTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ff5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORIES = \"Data/Histories.json\"\n",
    "TOKENS_PATH = Path(\"Config/keys.json\")\n",
    "CONFIG_PATH = Path(\"Config/config.json\")\n",
    "\n",
    "LLM_CLIENT = None\n",
    "HF_DATASET = None\n",
    "REASON_PROMPT = \"\"\n",
    "CRITIC_PROMPT = \"\"\n",
    "CONFIG = {}\n",
    "\n",
    "TOKENS = UTL.read_json(TOKENS_PATH)\n",
    "CONFIG = UTL.read_json(CONFIG_PATH)\n",
    "\n",
    "HF_REPO_ID = CONFIG[\"models\"][\"local_model\"][\"hf_repo_id\"]\n",
    "HF_FILENAME = CONFIG[\"models\"][\"local_model\"][\"hf_filename\"]\n",
    "CRITICAL_MODEL = CONFIG[\"models\"][\"global_model\"][\"model_name\"]\n",
    "\n",
    "PROMPT_REASON_PATH = Path(CONFIG[\"paths\"][\"prompt_reason\"])\n",
    "PROMPT_CRITIC_PATH = Path(CONFIG[\"paths\"][\"prompt_critic\"])\n",
    "LOCAL_MODEL_DIR = Path(CONFIG[\"paths\"][\"local_model_dir\"])\n",
    "LOCAL_MODEL_PATH = LOCAL_MODEL_DIR / HF_FILENAME\n",
    "\n",
    "REASON_PROMPT = UTL.read_text(PROMPT_REASON_PATH)\n",
    "CRITIC_PROMPT = UTL.read_text(PROMPT_CRITIC_PATH)\n",
    "\n",
    "match (CONFIG, REASON_PROMPT, CRITIC_PROMPT):\n",
    "    case (False, _, _):\n",
    "        print(\"‚õî D·ª´ng ch∆∞∆°ng tr√¨nh do kh√¥ng t·∫£i ƒë∆∞·ª£c file config.\")\n",
    "        exit()\n",
    "    case (_, False, _) | (_, _, False):\n",
    "        print(\"‚õî D·ª´ng ch∆∞∆°ng tr√¨nh do kh√¥ng t·∫£i ƒë∆∞·ª£c file prompt.\")\n",
    "        exit()\n",
    "    case _:\n",
    "        print(\"‚úÖ T·∫•t c·∫£ file ƒë√£ t·∫£i th√†nh c√¥ng.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dbec5d",
   "metadata": {},
   "source": [
    "### HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataset():\n",
    "    \"\"\"T·∫£i dataset t·ª´ Hugging Face.\"\"\"\n",
    "    global HF_DATASET\n",
    "    DATASET_NAME = CONFIG[\"dataset\"][\"name\"]\n",
    "    DATASET_SPLIT = CONFIG[\"dataset\"].get(\"split\", \"train\")\n",
    "    \n",
    "    print(f\"üìò ƒêang t·∫£i dataset '{DATASET_NAME}' (split: {DATASET_SPLIT})...\")\n",
    "    try:\n",
    "        HF_DATASET = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
    "        print(f\"‚úÖ T·∫£i dataset th√†nh c√¥ng. (S·ªë l∆∞·ª£ng: {len(HF_DATASET)} m·∫´u)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi t·∫£i dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonParse(text: str):\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        match = regex.search(r\"\\{(?:[^{}]|(?R))*\\}\", text, flags=regex.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(0)\n",
    "            try:\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        raise ValueError(f\"‚ùå Kh√¥ng parse ƒë∆∞·ª£c JSON t·ª´ ph·∫£n h·ªìi:\\n{text}\")\n",
    "    \n",
    "def randomContent() -> str:\n",
    "    if HF_DATASET is None:\n",
    "        print(\"‚ùå L·ªói: Dataset ch∆∞a ƒë∆∞·ª£c t·∫£i. (HF_DATASET is None)\")\n",
    "        return None\n",
    "    try:\n",
    "        idx = random.randint(0, len(HF_DATASET) - 1)\n",
    "        sample = HF_DATASET[idx]\n",
    "        content = sample.get(\"article\") or sample.get(\"text\")\n",
    "        title = sample.get(\"headlines\", \"Kh√¥ng c√≥ ti√™u ƒë·ªÅ\")\n",
    "        if not content:\n",
    "            print(f\"‚ö†Ô∏è M·∫´u ng·∫´u nhi√™n (index {idx}) kh√¥ng c√≥ c·ªôt 'article' ho·∫∑c 'text', th·ª≠ l·∫°i...\")\n",
    "            return randomContent()\n",
    "        print(f\"üìò Ch·ªçn ng·∫´u nhi√™n m·ª•c: {title}\")\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi l·∫•y m·∫´u ng·∫´u nhi√™n t·ª´ dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "def averageScore(critical_output: dict) -> float:\n",
    "    \"\"\"T√≠nh ƒëi·ªÉm trung b√¨nh t·ª´ output JSON l·ªìng nhau c·ªßa critical model.\"\"\"\n",
    "    scoring_dict = critical_output.get(\"scoring\")\n",
    "    if not scoring_dict or not isinstance(scoring_dict, dict):\n",
    "        if \"error\" not in critical_output:\n",
    "             print(\"‚ö†Ô∏è L·ªói: Kh√¥ng t√¨m th·∫•y key 'scoring' trong output c·ªßa Critical.\")\n",
    "        return 0.0\n",
    "    keys = [\"factuality\", \"clarity\", \"logical_coherence\", \"coverage\", \"utility\", \"consistency\"]\n",
    "    vals = [scoring_dict[k] for k in keys if isinstance(scoring_dict.get(k), (int, float))]\n",
    "    return mean(vals) if vals else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm_client():\n",
    "    \"\"\"Kh·ªüi t·∫°o m√¥ h√¨nh LLM local duy nh·∫•t.\"\"\"\n",
    "    global LLM_CLIENT\n",
    "    print(f\"üìò Ki·ªÉm tra model local t·∫°i: {LOCAL_MODEL_PATH}\")\n",
    "    if not LOCAL_MODEL_PATH.exists():\n",
    "        print(f\"‚ö†Ô∏è Model ch∆∞a t·ªìn t·∫°i. B·∫Øt ƒë·∫ßu t·∫£i '{HF_FILENAME}' t·ª´ '{HF_REPO_ID}'...\")\n",
    "        LOCAL_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            hf_hub_download(\n",
    "                repo_id=HF_REPO_ID,\n",
    "                filename=HF_FILENAME,\n",
    "                local_dir=LOCAL_MODEL_DIR,\n",
    "                local_dir_use_symlinks=False,\n",
    "                resume_download=True\n",
    "            )\n",
    "            print(\"‚úÖ T·∫£i model th√†nh c√¥ng.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi t·∫£i model: {e}\")\n",
    "            return \n",
    "    else:\n",
    "        print(\"üëç Model ƒë√£ c√≥ s·∫µn.\")\n",
    "\n",
    "    print(f\"üìò ƒêang t·∫£i model local t·ª´: {LOCAL_MODEL_PATH}\")\n",
    "    try:\n",
    "        LLM_CLIENT = Llama(\n",
    "            model_path=str(LOCAL_MODEL_PATH),\n",
    "            n_gpu_layers=CONFIG[\"llama_cpp_params\"][\"n_gpu_layers\"],\n",
    "            n_ctx=CONFIG[\"llama_cpp_params\"][\"n_ctx\"],\n",
    "            verbose=False\n",
    "        )\n",
    "        print(\"‚úÖ T·∫£i model local (LLM_CLIENT) th√†nh c√¥ng.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi t·∫£i model local: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb37d5",
   "metadata": {},
   "source": [
    "### RUNNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasoningRun(text: str, feedback: str | None = None) -> str:\n",
    "    \"\"\"Ch·∫°y reasoning. N·∫øu c√≥ feedback, n√≥ s·∫Ω ch·∫°y ·ªü ch·∫ø ƒë·ªô 'refine'.\"\"\"\n",
    "    if LLM_CLIENT is None:\n",
    "        print(\"‚ùå L·ªói: reasoningRun kh√¥ng th·ªÉ ch·∫°y v√¨ LLM_CLIENT ch∆∞a ƒë∆∞·ª£c t·∫£i.\")\n",
    "        return \"\"\n",
    "        \n",
    "    if feedback:\n",
    "        prompt = (\n",
    "            f\"<|user|>\\nB·∫°n ƒë√£ t·∫°o ra m·ªôt b·∫£n t√≥m t·∫Øt tr∆∞·ªõc ƒë√≥. \"\n",
    "            f\"B·∫£n t√≥m t·∫Øt ƒë√≥ ƒë√£ ƒë∆∞·ª£c ƒë√°nh gi√° v·ªõi ph·∫£n h·ªìi sau:\\n\"\n",
    "            f\"---BEGIN FEEDBACK---\\n{feedback}\\n---END FEEDBACK---\\n\\n\"\n",
    "            f\"Vui l√≤ng t·∫°o l·∫°i reasoning trace v√† t√≥m t·∫Øt, c√≥ t√≠nh ƒë·∫øn ph·∫£n h·ªìi n√†y. \"\n",
    "            f\"S·ª≠ d·ª•ng l·∫°i vƒÉn b·∫£n g·ªëc d∆∞·ªõi ƒë√¢y.\\n\\n\"\n",
    "            f\"VƒÉn b·∫£n g·ªëc:\\n{text}<|end|>\\n<|assistant|>\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = f\"<|user|>\\n{REASON_PROMPT}\\n\\n{text}<|end|>\\n<|assistant|>\"\n",
    "    \n",
    "    print(f\"prompt (local): {prompt}...\")\n",
    "\n",
    "    try:\n",
    "        completion = LLM_CLIENT(\n",
    "            prompt,\n",
    "            max_tokens=CONFIG[\"generation_params\"][\"max_new_tokens\"],\n",
    "            temperature=CONFIG[\"generation_params\"][\"temperature\"],\n",
    "            top_p=CONFIG[\"generation_params\"][\"top_p\"],\n",
    "            stop=[\"<|end|>\", \"<|endoftext|>\", \"</s>\"] \n",
    "        )\n",
    "        \n",
    "        if \"choices\" in completion and len(completion[\"choices\"]) > 0:\n",
    "            return completion[\"choices\"][0][\"text\"].strip()\n",
    "        else:\n",
    "            return str(completion).strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi ch·∫°y reasoningRun (local): {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criticalRun(source_text: str, reasoning_output: str) -> dict:\n",
    "    \"\"\"Ch·∫°y critical B·∫∞NG M√î H√åNH LOCAL, tr·∫£ v·ªÅ dict JSON.\"\"\"\n",
    "    if LLM_CLIENT is None:\n",
    "        return {\"error\": \"LLM client not initialized\"}\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    {CRITIC_PROMPT}\n",
    "\n",
    "    [Reasoning trace]:\n",
    "    {reasoning_output}\n",
    "\n",
    "    [VƒÉn b·∫£n g·ªëc]:\n",
    "    {source_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    final_prompt = f\"<|user|>\\n{user_prompt}<|end|>\\n<|assistant|>\"\n",
    "\n",
    "    try:\n",
    "        completion = LLM_CLIENT(\n",
    "            final_prompt,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.2,\n",
    "            top_p=0.9,\n",
    "            stop=[\"<|end|>\", \"```\"]\n",
    "        )\n",
    "\n",
    "        if \"choices\" not in completion or len(completion[\"choices\"]) == 0:\n",
    "            raise ValueError(\"M√¥ h√¨nh local (critical) kh√¥ng tr·∫£ v·ªÅ n·ªôi dung.\")\n",
    "\n",
    "        raw_output = completion[\"choices\"][0][\"text\"].strip()\n",
    "        if not raw_output:\n",
    "            raise ValueError(\"M√¥ h√¨nh local (critical) tr·∫£ v·ªÅ ph·∫£n h·ªìi r·ªóng.\")\n",
    "\n",
    "        try:\n",
    "            parsed_json = jsonParse(raw_output)\n",
    "            return parsed_json\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"‚ö†Ô∏è L·ªói parse JSON t·ª´ m√¥ h√¨nh local: {e}\")\n",
    "            print(f\"--- RAW OUTPUT T·ª™ PHI-3 (CRITICAL) ---\")\n",
    "            print(raw_output)\n",
    "            print(f\"----------------------------------------\")\n",
    "            return {\"error\": \"Failed to parse JSON from local model\", \"raw_response\": raw_output}\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"‚ùå L·ªói khi g·ªçi LLM (critical): {str(e)}\"\n",
    "        print(error_message)\n",
    "        return {\"error\": error_message}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be361b",
   "metadata": {},
   "source": [
    "### MAIN FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFlow(source_text: str, \n",
    "             max_iters=CONFIG[\"flow_params\"][\"max_iters\"], \n",
    "             min_improve=CONFIG[\"flow_params\"][\"min_improve\"]):\n",
    "    \n",
    "    best_reason, best_score = None, 0\n",
    "    history = []\n",
    "    current_feedback = None\n",
    "    current_reasoning = \"\"\n",
    "\n",
    "    for step in range(1, max_iters + 1):\n",
    "        print(f\"\\nüîÑ V√≤ng {step} ...\")\n",
    "        \n",
    "        current_reasoning = reasoningRun(source_text, current_feedback)\n",
    "        \n",
    "        artifact_marker = \"CV=\" \n",
    "        if artifact_marker in current_reasoning:\n",
    "            print(f\"‚ö†Ô∏è Ph√°t hi·ªán artifact '{artifact_marker}', ƒëang c·∫Øt b·ªè...\")\n",
    "            artifact_index = current_reasoning.find(artifact_marker)\n",
    "            current_reasoning = current_reasoning[:artifact_index].strip()\n",
    "        \n",
    "        if not current_reasoning:\n",
    "            print(\"‚õî Reasoning tr·∫£ v·ªÅ r·ªóng, d·ª´ng v√≤ng l·∫∑p.\")\n",
    "            break\n",
    "            \n",
    "        print(f\"\\nüîÑ Reaoning Result: {current_reasoning}\")\n",
    "        \n",
    "        critical_output = criticalRun(source_text, current_reasoning)\n",
    "        \n",
    "        if critical_output.get(\"error\"):\n",
    "            print(f\"‚õî L·ªói t·ª´ Critical: {critical_output['error']}, d·ª´ng v√≤ng l·∫∑p.\")\n",
    "            break\n",
    "        \n",
    "        average_score = averageScore(critical_output)\n",
    "        \n",
    "        current_feedback = critical_output.get(\"feedback_text\", \"\") \n",
    "\n",
    "        print(f\"üìä ƒêi·ªÉm TBC: {average_score:.2f}\")\n",
    "        print(f\"üìù Nh·∫≠n x√©t (To√†n b·ªô JSON): {json.dumps(critical_output, ensure_ascii=False, indent=2)}\\n\")\n",
    "\n",
    "        history.append({\n",
    "            \"round\": step, \n",
    "            \"score\": average_score, \n",
    "            \"reasoning\": current_reasoning, \n",
    "            \"evaluation\": critical_output.get(\"scoring\", {}),\n",
    "            \"feedback\": current_feedback\n",
    "        })\n",
    "        \n",
    "        if average_score > best_score + min_improve:\n",
    "            best_reason, best_score = current_reasoning, average_score\n",
    "            print(f\"üìà C·∫£i thi·ªán t·ªët, ƒëi·ªÉm m·ªõi: {best_score:.2f}\")\n",
    "            if average_score >= 4.8:\n",
    "                print(\"üéâ ƒê·∫°t ƒëi·ªÉm cao, d·ª´ng s·ªõm.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"‚õî Kh√¥ng c·∫£i thi·ªán ƒë√°ng k·ªÉ, d·ª´ng.\")\n",
    "            break\n",
    "\n",
    "    return {\"best_reasoning\": best_reason, \"best_score\": best_score, \"history\": history}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf1d09",
   "metadata": {},
   "source": [
    "### RUN MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ec45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- G·ªåI C√ÅC H√ÄM KH·ªûI T·∫†O ---\n",
    "    initialize_llm_client()\n",
    "    initialize_dataset()\n",
    "    \n",
    "    # ‚¨ÖÔ∏è Ch·ªâ c·∫ßn ki·ªÉm tra 2 th√†nh ph·∫ßn\n",
    "    if LLM_CLIENT is None or HF_DATASET is None: \n",
    "        print(\"‚õî Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu mainFlow (model ho·∫∑c dataset ch∆∞a ƒë∆∞·ª£c t·∫£i).\")\n",
    "        print(\"Vui l√≤ng ki·ªÉm tra l·∫°i l·ªói ·ªü tr√™n.\")\n",
    "        exit()\n",
    "        \n",
    "    try:\n",
    "        inputPara = randomContent()\n",
    "        if inputPara is None:\n",
    "            print(\"‚õî Kh√¥ng t·∫£i ƒë∆∞·ª£c n·ªôi dung test data, d·ª´ng ch∆∞∆°ng tr√¨nh.\")\n",
    "            exit()\n",
    "            \n",
    "        flow_params = CONFIG.get(\"flow_params\", {})\n",
    "        result = mainFlow(\n",
    "            inputPara,\n",
    "            max_iters=flow_params.get(\"max_iters\", 3),\n",
    "            min_improve=flow_params.get(\"min_improve\", 0.05)\n",
    "        )\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üéØ K·∫æT QU·∫¢ CU·ªêI C√ôNG üéØ\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        final_output = {\n",
    "            \"best_score\": result[\"best_score\"],\n",
    "            \"best_reasoning\": result[\"best_reasoning\"]\n",
    "        }\n",
    "        \n",
    "        print(json.dumps(final_output, ensure_ascii=False, indent=2))\n",
    "        \n",
    "        UTL.insert_json(result[\"history\"], HISTORIES, indent=2)\n",
    "        print(f\"\\nüìù L·ªãch s·ª≠ ch·∫°y ƒë·∫ßy ƒë·ªß ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{HISTORIES}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën trong main: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bruh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
